{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c5b9025-6282-4386-abae-975126652ba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T08:18:55.254044428Z",
     "start_time": "2023-07-04T08:18:54.999179894Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a670217-3504-4450-99ea-2d7a1e74b3d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T08:18:55.285230975Z",
     "start_time": "2023-07-04T08:18:55.047648881Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2b6facc-6719-41fd-8c3c-ce72612e7388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T08:18:55.285909480Z",
     "start_time": "2023-07-04T08:18:55.049401662Z"
    }
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(1,'/data/alex/cell_seg/mae-main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b83f4637-d6f7-4063-9ee1-0eb7082b7582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T08:18:55.287103846Z",
     "start_time": "2023-07-04T08:18:55.050494876Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.random' has no attribute 'BitGenerator'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_27969/2598782469.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtissuenetdata\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mSeprtSeg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/topo_cell_seg/tissuenetdata.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mskimage\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtransform\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0;31m# numpy compat\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mpandas\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompat\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mis_numpy_dev\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_is_numpy_dev\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/compat/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mpandas\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_typing\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m from pandas.compat.numpy import (\n\u001B[1;32m     16\u001B[0m     \u001B[0mis_numpy_dev\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_typing.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    118\u001B[0m     \u001B[0mArrayLike\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m     \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGenerator\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 120\u001B[0;31m     \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBitGenerator\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    121\u001B[0m     \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRandomState\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    122\u001B[0m ]\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'numpy.random' has no attribute 'BitGenerator'"
     ]
    }
   ],
   "source": [
    "from tissuenetdata import SeprtSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce13ec7-4af2-4a60-8e62-2b5732a5cba2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.129879671Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train = SeprtSeg(root_dir = '../imgs/train')\n",
    "dataset_val = SeprtSeg(root_dir = '../imgs/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e136a-cea3-4ca3-b743-b4d304cdcc29",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.130979304Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train.__getitem__(0)['tissuelabel'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7b4ae-dd26-4cdc-ada2-c4812efe91f1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.133243583Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 10\n",
    "pin_mem = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2cdd7a-feb7-4845-b994-0353f8632aef",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.134083354Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_train.__getitem__(0)\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val, shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_mem,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f319d4db-cef9-480b-8086-20f3cf215f25",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.134970578Z"
    }
   },
   "outputs": [],
   "source": [
    "from swinunet import SwinUnet\n",
    "# from models_vit_seg_2 import vit_seg_large\n",
    "# import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a25cb6-d9be-47f3-858b-2cb892b1ad61",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.135441396Z"
    }
   },
   "outputs": [],
   "source": [
    "# net = smp.UnetPlusPlus(\n",
    "#     encoder_name = 'resnext50_32x4d',\n",
    "#     in_channels = 2,\n",
    "#     # decoder_attention_type = 'scse',\n",
    "#     decoder_use_batchnorm = True,\n",
    "#     activation = 'sigmoid',\n",
    "#     classes=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc84008-c935-4087-8986-588185ac94bd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.135936605Z"
    }
   },
   "outputs": [],
   "source": [
    "net = SwinUnet(\n",
    "    num_classes=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32596b69-9dc5-4e7f-82cc-ee0388920bc1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.136908068Z"
    }
   },
   "outputs": [],
   "source": [
    "# net = vit_seg_large()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f0537-2734-4b0e-8d0d-dcaf4e9a7f4f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.137432191Z"
    }
   },
   "outputs": [],
   "source": [
    "out = net(\n",
    "    torch.randn(10,2,256,256)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed46486-0818-4acc-a3ef-861d3c90a316",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.137986588Z"
    }
   },
   "outputs": [],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265dd2cf-1749-421a-af31-f81af78c7edb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.138573873Z"
    }
   },
   "outputs": [],
   "source": [
    "out.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5054b3a-4252-4e1c-ac1a-435ef1334e9a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.139435046Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf54ef-4bf0-46e4-bf2a-869b565c1509",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.140611103Z"
    }
   },
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "###\n",
    "print(\"to {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e6e48-f77b-4da3-89f2-59d2dbcf60b8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.144934540Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-3* 32/256\n",
    "min_lr = 1e-6\n",
    "weight_decay = 0.05\n",
    "layer_decay = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03127b9-b3e4-4b03-a2f2-90776c42a23a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.148187477Z"
    }
   },
   "outputs": [],
   "source": [
    "# import util.lr_decay as lrd\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ed952-20b0-4c40-b547-90d99d1976d4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.155392372Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(net, (10,2,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee1ed3-4811-49d1-bf16-306a73ed64ee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.158969457Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(net.blocks) + len(net.seg_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04186c11-f3f5-4373-a113-1bb685901c11",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.160095689Z"
    }
   },
   "outputs": [],
   "source": [
    "def param_groups_lrd(model, weight_decay=0.05, no_weight_decay_list=[], layer_decay=.75):\n",
    "    \"\"\"\n",
    "    Parameter groups for layer-wise lr decay\n",
    "    Following BEiT: https://github.com/microsoft/unilm/blob/master/beit/optim_factory.py#L58\n",
    "    \"\"\"\n",
    "    param_group_names = {}\n",
    "    param_groups = {}\n",
    "\n",
    "    num_layers = 32 + 1#len(model.swin_unet.layers) + 1\n",
    "\n",
    "    layer_scales = list(layer_decay ** (num_layers - i) for i in range(num_layers + 1))\n",
    "\n",
    "    for n, p in model.named_parameters():\n",
    "        if not p.requires_grad:\n",
    "            continue\n",
    "\n",
    "        # no decay: all 1D parameters and model specific ones\n",
    "        if p.ndim == 1 or n in no_weight_decay_list:\n",
    "            g_decay = \"no_decay\"\n",
    "            this_decay = 0.\n",
    "        else:\n",
    "            g_decay = \"decay\"\n",
    "            this_decay = weight_decay\n",
    "            \n",
    "        layer_id = get_layer_id_for_vit(n, num_layers)\n",
    "        group_name = \"layer_%d_%s\" % (layer_id, g_decay)\n",
    "\n",
    "        if group_name not in param_group_names:\n",
    "            this_scale = layer_scales[layer_id]\n",
    "\n",
    "            param_group_names[group_name] = {\n",
    "                \"lr_scale\": this_scale,\n",
    "                \"weight_decay\": this_decay,\n",
    "                \"params\": [],\n",
    "            }\n",
    "            param_groups[group_name] = {\n",
    "                \"lr_scale\": this_scale,\n",
    "                \"weight_decay\": this_decay,\n",
    "                \"params\": [],\n",
    "            }\n",
    "\n",
    "        param_group_names[group_name][\"params\"].append(n)\n",
    "        param_groups[group_name][\"params\"].append(p)\n",
    "\n",
    "    # print(\"parameter groups: \\n%s\" % json.dumps(param_group_names, indent=2))\n",
    "\n",
    "    return list(param_groups.values())\n",
    "\n",
    "def get_layer_id_for_resnext(name, num_layers):\n",
    "    \"\"\"\n",
    "    Assign a parameter with its layer id\n",
    "    Following BEiT: https://github.com/microsoft/unilm/blob/master/beit/optim_factory.py#L33\n",
    "    \"\"\"\n",
    "    # print(name)\n",
    "    if name in ['cls_token', 'pos_embed']:\n",
    "        return 0\n",
    "    elif 'patch_embed' in name:\n",
    "        return 0\n",
    "    elif 'layer' in name:\n",
    "        nmlst = name.split('.')\n",
    "        return int(nmlst[1][-1])*5 + int(nmlst[2])\n",
    "    else:\n",
    "        return num_layers\n",
    "\n",
    "\n",
    "def get_layer_id_for_vit(name, num_layers):\n",
    "    \"\"\"\n",
    "    Assign a parameter with its layer id\n",
    "    Following BEiT: https://github.com/microsoft/unilm/blob/master/beit/optim_factory.py#L33\n",
    "    \"\"\"\n",
    "    print(name)\n",
    "    if name in ['cls_token', 'pos_embed']:\n",
    "        return 0\n",
    "    elif 'patch_embed' in name:\n",
    "        return 0\n",
    "    elif 'blocks' in name:\n",
    "        # print(name.split(\".\"))\n",
    "        return int(name.split('.')[2]) + 1\n",
    "    else:\n",
    "        return num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e35c8f9-55a9-488b-9cfd-106992169e91",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.160694693Z"
    }
   },
   "outputs": [],
   "source": [
    "param_groups = param_groups_lrd(\n",
    "    net, \n",
    "    weight_decay,\n",
    "        # no_weight_decay_list=model_without_ddp.no_weight_decay(),\n",
    "    layer_decay=layer_decay\n",
    ")\n",
    "optimizer = torch.optim.AdamW(param_groups, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68be42-8fcd-44ac-b9bf-8dc47ca2c9f8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.161402992Z"
    }
   },
   "outputs": [],
   "source": [
    "## Only for MAE vit:\n",
    "# from util.pos_embed import interpolate_pos_embed\n",
    "\n",
    "# finetune = '../p65maskr/checkpoint-249.pth'\n",
    "\n",
    "# checkpoint = torch.load(finetune, map_location='cpu')\n",
    "\n",
    "# print(\"Load pre-trained checkpoint from: %s\" % finetune)\n",
    "# checkpoint_model = checkpoint['model']\n",
    "# state_dict = net.state_dict()\n",
    "# for k in ['head.weight', 'head.bias']:\n",
    "#     if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "#         print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "#         del checkpoint_model[k]\n",
    "\n",
    "#         # interpolate position embedding\n",
    "# interpolate_pos_embed(net, checkpoint_model)\n",
    "\n",
    "#         # load pre-trained model\n",
    "# msg = net.load_state_dict(checkpoint_model, strict=False)\n",
    "# print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093cbee0-0028-4515-a617-a4480a770389",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.205384889Z"
    }
   },
   "outputs": [],
   "source": [
    "from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "import util.misc as misc\n",
    "from timm.data import Mixup\n",
    "import math\n",
    "import sys\n",
    "from typing import Iterable, Optional\n",
    "# import util.lr_sched as lr_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963441e6-6b52-4b94-972b-de505ca7dc4e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.206138479Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_scaler = NativeScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace208a5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.206594140Z"
    }
   },
   "outputs": [],
   "source": [
    "# del topo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f13d8-c9ec-4e56-be44-4ebeeef22132",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.206982517Z"
    }
   },
   "outputs": [],
   "source": [
    "from tp_loss import topo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e5e557-73b7-4156-a34d-ffad23a2d444",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.207474521Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = topo_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77e974-05b0-4dd8-bb89-1f35720c6ed9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.207882436Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "from util.misc import is_main_process\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, num_epochs=250, warmup_epochs=10, lr=lr, min_lr=min_lr):\n",
    "    \"\"\"Decay the learning rate with half-cycle cosine after warmup\"\"\"\n",
    "    # print(num_epochs)\n",
    "    if epoch < warmup_epochs:\n",
    "        lr = lr * epoch / warmup_epochs \n",
    "    else:\n",
    "        lr = min_lr + (lr - min_lr) * 0.5 * \\\n",
    "            (1. + math.cos(math.pi * (epoch - warmup_epochs) / (num_epochs - warmup_epochs)))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if \"lr_scale\" in param_group:\n",
    "            param_group[\"lr\"] = lr * param_group[\"lr_scale\"]\n",
    "        else:\n",
    "            param_group[\"lr\"] = lr\n",
    "    return lr\n",
    "\n",
    "def save_on_master(*args, **kwargs):\n",
    "    if is_main_process():\n",
    "        torch.save(*args, **kwargs)\n",
    "\n",
    "def save_model(output_dirnm, epoch, model, model_without_ddp, optimizer, loss_scaler):\n",
    "    output_dir = Path(output_dirnm)\n",
    "    epoch_name = str(epoch)\n",
    "    if loss_scaler is not None:\n",
    "        checkpoint_paths = [output_dir / ('checkpoint-%s.pth' % epoch_name)]\n",
    "        for checkpoint_path in checkpoint_paths:\n",
    "            to_save = {\n",
    "                'model': model_without_ddp.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'scaler': loss_scaler.state_dict()\n",
    "            }\n",
    "\n",
    "            save_on_master(to_save, checkpoint_path)\n",
    "    else:\n",
    "        client_state = {'epoch': epoch}\n",
    "        model.save_checkpoint(save_dir=output_dinmr, tag=\"checkpoint-%s\" % epoch_name, client_state=client_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacce029-0b40-4039-a779-252e7555a333",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.208222565Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model: torch.nn.Module, criterion: torch.nn.Module,\n",
    "                    data_loader: Iterable, optimizer: torch.optim.Optimizer,\n",
    "                    device: torch.device, epoch: int, loss_scaler, max_norm: float = 0,\n",
    "                    mixup_fn: Optional[Mixup] = None, log_writer=None,\n",
    "                    args=None):\n",
    "    model.train(True)\n",
    "    metric_logger = misc.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', misc.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    metric_logger.add_meter('mse', misc.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    metric_logger.add_meter('mmt', misc.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "    print_freq = 20\n",
    "\n",
    "    accum_iter = 1\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if log_writer is not None:\n",
    "        print('log_dir: {}'.format(log_writer.log_dir))\n",
    "        \n",
    "    for item in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
    "        print(item[1].keys())\n",
    "        break\n",
    "    \n",
    "    \n",
    "    for data_iter_step, datum in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
    "\n",
    "        # we use a per iteration (instead of per epoch) lr scheduler\n",
    "        if data_iter_step % accum_iter == 0:\n",
    "            adjust_learning_rate(optimizer, data_iter_step / len(data_loader) + epoch)\n",
    "        \n",
    "        samples, targets = datum['image'], datum['ind']\n",
    "        samples = samples.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        if mixup_fn is not None:\n",
    "            samples, targets = mixup_fn(samples, targets)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(samples)\n",
    "            loss, mse_v, mmt_v = criterion(outputs, targets)\n",
    "\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "            sys.exit(1)\n",
    "\n",
    "        loss /= accum_iter\n",
    "        loss_scaler(loss, optimizer, clip_grad=max_norm,\n",
    "                    parameters=model.parameters(), create_graph=False,\n",
    "                    update_grad=(data_iter_step + 1) % accum_iter == 0)\n",
    "        if (data_iter_step + 1) % accum_iter == 0:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        metric_logger.update(loss=loss_value)\n",
    "        metric_logger.update(mse=mse_v)\n",
    "        metric_logger.update(mmt=mmt_v)\n",
    "        \n",
    "        min_lr = 10.\n",
    "        max_lr = 0.\n",
    "        for group in optimizer.param_groups:\n",
    "            min_lr = min(min_lr, group[\"lr\"])\n",
    "            max_lr = max(max_lr, group[\"lr\"])\n",
    "\n",
    "        metric_logger.update(lr=max_lr)\n",
    "\n",
    "        loss_value_reduce = misc.all_reduce_mean(loss_value)\n",
    "        mse_reduce = misc.all_reduce_mean(mse_v)\n",
    "        mmt_reduce = misc.all_reduce_mean(mmt_v)\n",
    "        if log_writer is not None and (data_iter_step + 1) % accum_iter == 0:\n",
    "            \"\"\" We use epoch_1000x as the x-axis in tensorboard.\n",
    "            This calibrates different curves when batch size changes.\n",
    "            \"\"\"\n",
    "            epoch_1000x = int((data_iter_step / len(data_loader) + epoch) * 1000)\n",
    "            log_writer.add_scalar('loss', loss_value_reduce, epoch_1000x)\n",
    "            log_writer.add_scalar('lr', max_lr, epoch_1000x)\n",
    "\n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    print(\"Averaged stats:\", metric_logger)\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(data_loader,criterion, model, device):\n",
    "\n",
    "    metric_logger = misc.MetricLogger(delimiter=\"  \")\n",
    "    header = 'Validation:'\n",
    "\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for batch in metric_logger.log_every(data_loader, 10, header):\n",
    "        images = batch['image']\n",
    "        targets = batch['ind']\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        # compute output\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(images)\n",
    "            loss, mse_v, mmt_v = criterion(output, targets)\n",
    "            \n",
    "        batch_size = images.shape[0]\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.update(mse=mse_v)\n",
    "        metric_logger.update(mmt=mmt_v)\n",
    "        \n",
    "\n",
    "    # gather the stats from all processes\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    print('loss {losses.global_avg:.3f}'\n",
    "          .format(losses=metric_logger.loss))\n",
    "\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25ec1d-944a-4247-9d7c-1bcf273a8848",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.208581446Z"
    }
   },
   "outputs": [],
   "source": [
    "out_dir = '../experiments/nuc_test_4_17_2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b56de6-080d-4912-bb69-d4020cf51653",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.209013579Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(out_dir, exist_ok=True)\n",
    "log_writer = SummaryWriter(log_dir=out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8850e0e-5a9c-4d18-b2c1-c00f78e31723",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.209427796Z"
    }
   },
   "outputs": [],
   "source": [
    "n_parameters = sum(p.numel() for p in net.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a419b7d-fe04-4b56-aae6-56a76588950b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.209731786Z"
    }
   },
   "outputs": [],
   "source": [
    "config_dic = {\n",
    "    'lr' : 1e-3* 32/256,\n",
    "    'min_lr' : 1e-6,\n",
    "    'weight_decay' : 0.05,\n",
    "    'layer_decay' : 0.75\n",
    "}   \n",
    "with open(os.path.join(out_dir, \"config_model.txt\"),mode=\"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(config_dic) + \"\\n\")\n",
    "          \n",
    "for epoch in range(0, 250):\n",
    "    train_stats = train_one_epoch(\n",
    "        net, criterion, data_loader_train,\n",
    "        optimizer, device, epoch, loss_scaler,\n",
    "        None, None,\n",
    "        log_writer=log_writer,\n",
    "    )\n",
    "\n",
    "    save_model(\n",
    "        output_dirnm= out_dir, model=net, model_without_ddp=net, optimizer=optimizer,\n",
    "        loss_scaler=loss_scaler, epoch=epoch)\n",
    "    test_stats = evaluate(data_loader_val, criterion, net, device)\n",
    "    log_writer.add_scalar('val/val_loss', test_stats['loss'], epoch)\n",
    "    log_writer.add_scalar('val/mse_loss', test_stats['mse'], epoch)\n",
    "    log_writer.add_scalar('val/mmt_loss', test_stats['mmt'], epoch)\n",
    "    log_writer.add_scalar('train/train_loss', train_stats['loss'], epoch)\n",
    "    log_writer.add_scalar('train/mse_loss', train_stats['mse'], epoch)\n",
    "    log_writer.add_scalar('train/mmt_loss', train_stats['mmt'], epoch)\n",
    "    \n",
    "    \n",
    "    log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
    "                        **{f'test_{k}': v for k, v in test_stats.items()},\n",
    "                        'epoch': epoch,\n",
    "                        'n_parameters': n_parameters}\n",
    "    \n",
    "    if log_writer is not None:\n",
    "        log_writer.flush()\n",
    "    with open(os.path.join( out_dir, \"log.txt\"), mode=\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(log_stats) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3679f4-66df-4be8-968d-d2735e99e3f6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T08:18:55.209948208Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
